{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68b9ced",
   "metadata": {},
   "source": [
    "### SEC FILINGS ANALYSIS\n",
    "#### Ground truth financial health and event triggers\n",
    "Filing Types:\n",
    "* 10-K: Annual report, comprehensive overview (financials, business operations, risks). Filed within 60–90 days after fiscal year-end.\n",
    "* 10-Q: Quarterly report, less detailed but includes financials and updates. Filed within 40–45 days after quarter-end.\n",
    "* 8-K: Current report for material events (e.g., acquisitions, executive changes, earnings releases). Filed within 4 business days of the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13e5c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from transformers import pipeline\n",
    "from lxml import etree\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1d584",
   "metadata": {},
   "source": [
    "### 8-K Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c386a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sec_header(file_content):\n",
    "    \"\"\"Extract metadata from SEC-HEADER section.\"\"\"\n",
    "    header_data = {\n",
    "        'accession_number': None,\n",
    "        'company_name': None,\n",
    "        'filing_date': None,\n",
    "        'report_date': None,\n",
    "        'items': [],\n",
    "        'cik': None,\n",
    "        'sic': None\n",
    "    }\n",
    "    \n",
    "    # Extract header section\n",
    "    header_match = re.search(r'<SEC-HEADER>(.*?)</SEC-HEADER>', file_content, re.DOTALL)\n",
    "    if not header_match:\n",
    "        return header_data\n",
    "    \n",
    "    header_text = header_match.group(1)\n",
    "    \n",
    "    # Extract key fields\n",
    "    header_data['accession_number'] = re.search(r'ACCESSION NUMBER:\\s*(\\S+)', header_text).group(1) if re.search(r'ACCESSION NUMBER:\\s*(\\S+)', header_text) else None\n",
    "    header_data['company_name'] = re.search(r'COMPANY CONFORMED NAME:\\s*(.+)', header_text).group(1) if re.search(r'COMPANY CONFORMED NAME:\\s*(.+)', header_text) else None\n",
    "    header_data['filing_date'] = re.search(r'FILED AS OF DATE:\\s*(\\d{8})', header_text).group(1) if re.search(r'FILED AS OF DATE:\\s*(\\d{8})', header_text) else None\n",
    "    header_data['report_date'] = re.search(r'CONFORMED PERIOD OF REPORT:\\s*(\\d{8})', header_text).group(1) if re.search(r'CONFORMED PERIOD OF REPORT:\\s*(\\d{8})', header_text) else None\n",
    "    header_data['cik'] = re.search(r'CENTRAL INDEX KEY:\\s*(\\S+)', header_text).group(1) if re.search(r'CENTRAL INDEX KEY:\\s*(\\S+)', header_text) else None\n",
    "    header_data['sic'] = re.search(r'STANDARD INDUSTRIAL CLASSIFICATION:\\s*.+\\[(\\d+)\\]', header_text).group(1) if re.search(r'STANDARD INDUSTRIAL CLASSIFICATION:\\s*.+\\[(\\d+)\\]', header_text) else None\n",
    "    \n",
    "    # Extract item information\n",
    "    items = re.findall(r'ITEM INFORMATION:\\s*(.+)', header_text)\n",
    "    header_data['items'] = items if items else []\n",
    "    \n",
    "    return header_data\n",
    "\n",
    "def parse_body_content(file_content):\n",
    "    \"\"\"Extract narrative content from the body, handling HTML/XBRL.\"\"\"\n",
    "    # Extract document section\n",
    "    doc_match = re.search(r'<DOCUMENT>.*?<TEXT>(.*?)</TEXT>', file_content, re.DOTALL)\n",
    "    if not doc_match:\n",
    "        return \"\"\n",
    "    \n",
    "    body_text = doc_match.group(1)\n",
    "    \n",
    "    # Parse HTML content\n",
    "    soup = BeautifulSoup(body_text, 'html.parser')\n",
    "    \n",
    "    # Remove scripts, styles, and other non-text elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "    \n",
    "    # Extract text\n",
    "    text = soup.get_text(separator=\" \", strip=True)\n",
    "    \n",
    "    # Clean up excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def process_8k_filings(root_dir):\n",
    "    \"\"\"Traverse directory and process all 8-K filings.\"\"\"\n",
    "    filings_data = []\n",
    "    \n",
    "    for stock_name in os.listdir(root_dir):\n",
    "        stock_path = os.path.join(root_dir, stock_name, '8-K')\n",
    "        if not os.path.exists(stock_path):\n",
    "            continue\n",
    "            \n",
    "        for accession_number in os.listdir(stock_path):\n",
    "            file_path = os.path.join(stock_path, accession_number, 'full-submission.txt')\n",
    "            if not os.path.exists(file_path):\n",
    "                continue\n",
    "                \n",
    "            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "                \n",
    "            # Parse header and body\n",
    "            header = parse_sec_header(content)\n",
    "            body_text = parse_body_content(content)\n",
    "            \n",
    "            filings_data.append({\n",
    "                'stock': stock_name,\n",
    "                'accession_number': header['accession_number'],\n",
    "                'company_name': header['company_name'],\n",
    "                'filing_date': header['filing_date'],\n",
    "                'report_date': header['report_date'],\n",
    "                'cik': header['cik'],\n",
    "                'sic': header['sic'],\n",
    "                'items': header['items'],\n",
    "                'body_text': body_text\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(filings_data)\n",
    "\n",
    "root_dir = 'sec_finra_data/sec_filings/sec-edgar-filings'\n",
    "filings_df = process_8k_filings(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72a825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filings_df.to_csv('processed_8k_filings.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc6829",
   "metadata": {},
   "source": [
    "* **Risk Score:** A numerical score based on the potential impact of event types on stock prices.\n",
    "* **Sentiment Analysis:** FinBERT is used to analyze the sentiment of the narrative text, which can indicate the tone.\n",
    "* **Date Lag:** Measures delays in reporting, which could suggest intentional timing to influence markets.\n",
    "* **Event Frequency:** High filing frequency may indicate attempts to manipulate market perception through frequent news."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3de9aa80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef6c223978640948f439044d2a56e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f4a6d76a334db2a759dcad3e600428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ff04532dbe4f9bae30eb45b0794b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "# Load FinBERT for sentiment analysis\n",
    "sentiment_analyzer = pipeline(\"sentiment-analysis\", model=\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "def assign_risk_score(items):\n",
    "    \"\"\"Assign risk score based on event types.\"\"\"\n",
    "    high_risk = [\"Results of Operations and Financial Condition\", \"Material Impairments\", \"Regulation FD Disclosure\"]\n",
    "    medium_risk = [\"Departure of Directors or Certain Officers\", \"Entry into a Material Definitive Agreement\"]\n",
    "    \n",
    "    for item in items:\n",
    "        if item in high_risk:\n",
    "            return 3\n",
    "        if item in medium_risk:\n",
    "            return 2\n",
    "    return 1\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"Get sentiment score using FinBERT.\"\"\"\n",
    "    try:\n",
    "        result = sentiment_analyzer(text[:512])[0]  # FinBERT has token limits\n",
    "        return result['label'], result['score']\n",
    "    except:\n",
    "        return \"neutral\", 0.0\n",
    "\n",
    "# Feature engineering\n",
    "filings_df['filing_date'] = pd.to_datetime(filings_df['filing_date'], format='%Y%m%d')\n",
    "filings_df['report_date'] = pd.to_datetime(filings_df['report_date'], format='%Y%m%d')\n",
    "filings_df['date_lag'] = (filings_df['filing_date'] - filings_df['report_date']).dt.days\n",
    "filings_df['risk_score'] = filings_df['items'].apply(assign_risk_score)\n",
    "\n",
    "# Sentiment analysis on body text\n",
    "filings_df['sentiment_label'], filings_df['sentiment_score'] = zip(*filings_df['body_text'].apply(get_sentiment))\n",
    "\n",
    "# Event frequency per stock per month\n",
    "filings_df['month'] = filings_df['filing_date'].dt.to_period('M')\n",
    "event_freq = filings_df.groupby(['stock', 'month']).size().reset_index(name='event_count')\n",
    "filings_df = filings_df.merge(event_freq, on=['stock', 'month'], how='left')\n",
    "\n",
    "filings_df.to_csv('engineered_8k_filings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0729780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
