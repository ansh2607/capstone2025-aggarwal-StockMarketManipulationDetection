{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import time\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from datetime import datetime\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sec_edgar_downloader import Downloader\n",
    "from sec_api import QueryApi, SecLitigationsApi, AaerApi\n",
    "from urllib.parse import urljoin\n",
    "from datasets import load_dataset\n",
    "\n",
    "import ssl\n",
    "import urllib3\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chosen Stocks\n",
    "1. GameStop (GME): Meme stock with documented pump-and-dump-like behavior in 2021.\n",
    "2. AMC Entertainment (AMC): Another meme stock with high volatility and social media influence. In same year 2021, short squeeze triggered by Reddit communities.\n",
    "3. Tilray Brands (TLRY): Cannabis stock, often volatile and targeted in pump-and-dump schemes.\n",
    "4. Sundial Growers (SNDL): Penny stock in the cannabis sector, prone to manipulation.\n",
    "5. Naked Brand (NAKD): Penny stock with historical pump-and-dump activity.\n",
    "6. Zomedica (ZOM): Biotech penny stock, often hyped on social media.\n",
    "7. Apple (AAPL): Blue-chip stock for insider trading analysis.\n",
    "8. Tesla (TSLA): Large-cap stock with high news coverage and volatility.\n",
    "9. Canoo (GOEV): Small-cap electric vehicle stock, volatile and prone to hype.\n",
    "10. Plug Power (PLUG): Small-cap energy stock, often targeted in manipulation schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = ['GME', 'AMC', 'TLRY', 'SNDL', 'NAKD', 'ZOM', 'AAPL', 'TSLA', 'GOEV', 'PLUG']\n",
    "# stocks = ['SNDL']\n",
    "form_types = ['10-K', '10-Q', '8-K']\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-12-31'\n",
    "intraday_stocks = ['GME', 'AMC', 'SNDL']  # Subset for intraday data\n",
    "intraday_year = 2021  # Focusing on 2021 for intraday due to API limits\n",
    "alpha_vantage_api_key = 'JMLBULM9O2APELTQ' \n",
    "sec_api_key = '72e3942a367fbcd428ad3a4cd4b2c0af7ebedf3e2d3097224b5cae926f0ac003'\n",
    "# output_dir = 'stock_data'\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "# output_dir2 = 'sec_finra_data'\n",
    "# os.makedirs(output_dir2, exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir2}/sec_filings\", exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir2}/sec_enforcement\", exist_ok=True)\n",
    "# os.makedirs(f\"{output_dir2}/finra_actions\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading daily data for GME...\n",
      "Saved GME_daily.csv\n",
      "Downloading daily data for AMC...\n",
      "Saved AMC_daily.csv\n",
      "Downloading daily data for TLRY...\n",
      "Saved TLRY_daily.csv\n",
      "Downloading daily data for SNDL...\n",
      "Saved SNDL_daily.csv\n",
      "Downloading daily data for NAKD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$NAKD: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No data for NAKD\n",
      "Downloading daily data for ZOM...\n",
      "Saved ZOM_daily.csv\n",
      "Downloading daily data for AAPL...\n",
      "Saved AAPL_daily.csv\n",
      "Downloading daily data for TSLA...\n",
      "Saved TSLA_daily.csv\n",
      "Downloading daily data for GOEV...\n",
      "Saved GOEV_daily.csv\n",
      "Downloading daily data for PLUG...\n",
      "Saved PLUG_daily.csv\n"
     ]
    }
   ],
   "source": [
    "# Collecting daily stock data using yfinance\n",
    "def collect_yfinance_data():\n",
    "    for stock in stocks:\n",
    "        try:\n",
    "            print(f\"Downloading daily data for {stock}...\")\n",
    "            ticker = yf.Ticker(stock)\n",
    "            df = ticker.history(start=start_date, end=end_date, interval='1d')\n",
    "            if not df.empty:\n",
    "                df = df[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "                df.to_csv(f\"{output_dir}/{stock}_daily.csv\")\n",
    "                print(f\"Saved {stock}_daily.csv\")\n",
    "            else:\n",
    "                print(f\"No data for {stock}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading {stock}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "collect_yfinance_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 10-K filings for SNDL...\n",
      "Saved 10-K filings for SNDL\n",
      "Downloading 10-Q filings for SNDL...\n",
      "Saved 10-Q filings for SNDL\n",
      "Downloading 8-K filings for SNDL...\n",
      "Saved 8-K filings for SNDL\n"
     ]
    }
   ],
   "source": [
    "# Initializing SEC downloader\n",
    "dl = Downloader(\"UOG\",\"anshulaggarwal2666@gmail.com\", f\"{output_dir2}/sec_filings\")\n",
    "\n",
    "# Collecting SEC filings (10-K, 10-Q, 8-K)\n",
    "def collect_sec_filings():\n",
    "    for stock in stocks:\n",
    "        for form_type in form_types:\n",
    "            try:\n",
    "                print(f\"Downloading {form_type} filings for {stock}...\")\n",
    "                dl.get(form_type, stock, after=start_date, before=end_date)\n",
    "                print(f\"Saved {form_type} filings for {stock}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading {form_type} for {stock}: {e}\")\n",
    "            time.sleep(0.1)\n",
    "\n",
    "collect_sec_filings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 17:57:36,572 - INFO - Attempting to load dataset: StephanAkkerman/stock-market-tweets-data\n",
      "2025-05-20 17:57:42,308 - INFO - Successfully loaded StephanAkkerman/stock-market-tweets-data\n",
      "2025-05-20 17:58:00,040 - INFO - Found 151336 tweets from StephanAkkerman/stock-market-tweets-data\n",
      "2025-05-20 17:58:00,048 - INFO - Fetching StockTwits data for GME\n",
      "2025-05-20 17:58:01,589 - INFO - Fetching StockTwits data for AMC\n",
      "2025-05-20 17:58:03,111 - INFO - Fetching StockTwits data for TLRY\n",
      "2025-05-20 17:58:05,168 - INFO - Fetching StockTwits data for SNDL\n",
      "2025-05-20 17:58:07,042 - INFO - Fetching StockTwits data for NAKD\n",
      "2025-05-20 17:58:07,397 - ERROR - Error fetching StockTwits for NAKD: 404 Client Error: Not Found for url: https://api.stocktwits.com/api/2/streams/symbol/NAKD.json\n",
      "2025-05-20 17:58:07,401 - INFO - Fetching StockTwits data for ZOM\n",
      "2025-05-20 17:58:07,684 - ERROR - Error fetching StockTwits for ZOM: 404 Client Error: Not Found for url: https://api.stocktwits.com/api/2/streams/symbol/ZOM.json\n",
      "2025-05-20 17:58:07,685 - INFO - Fetching StockTwits data for AAPL\n",
      "2025-05-20 17:58:08,974 - INFO - Fetching StockTwits data for TSLA\n",
      "2025-05-20 17:58:10,645 - INFO - Fetching StockTwits data for GOEV\n",
      "2025-05-20 17:58:12,034 - INFO - Fetching StockTwits data for PLUG\n",
      "2025-05-20 17:58:13,702 - INFO - No StockTwits posts found\n",
      "2025-05-20 17:58:14,903 - INFO - Saved data to twitter_data/stock_social_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-04-09 23:56:58+00:00</td>\n",
       "      <td>RT @TDANetwork: üìΩÔ∏è #TheWatchList panel assesse...</td>\n",
       "      <td>13</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020-04-09 23:56:51+00:00</td>\n",
       "      <td>$UMRX bouncing. EXTREMELY OVERSOLD #Coronaviru...</td>\n",
       "      <td>14</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-04-09 23:55:05+00:00</td>\n",
       "      <td>$AAPL 4h/1h\\n\\nSometimes these wedges break hi...</td>\n",
       "      <td>32</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-04-09 23:54:47+00:00</td>\n",
       "      <td>This week's Expired Signals are now published ...</td>\n",
       "      <td>33</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-04-09 23:54:28+00:00</td>\n",
       "      <td>$SPY $QQQ $VXX $AAPL $BA $MSFT\\n\\nGuys, I figu...</td>\n",
       "      <td>34</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923637</th>\n",
       "      <td>2020-07-16 00:04:02+00:00</td>\n",
       "      <td>RT @TATrades: Quick poll - how much do you (on...</td>\n",
       "      <td>938637</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923644</th>\n",
       "      <td>2020-07-16 00:03:39+00:00</td>\n",
       "      <td>RT @NukemosS: China retaliating on $AAPL</td>\n",
       "      <td>938644</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923652</th>\n",
       "      <td>2020-07-16 00:02:21+00:00</td>\n",
       "      <td>lows. This is shaping up for another nice sell...</td>\n",
       "      <td>938652</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923656</th>\n",
       "      <td>2020-07-16 00:01:48+00:00</td>\n",
       "      <td>@_SeanDavid I could make a good case for why $...</td>\n",
       "      <td>938656</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923668</th>\n",
       "      <td>2020-07-16 00:00:25+00:00</td>\n",
       "      <td>RT @MadMraket: We tend to spend lot of time in...</td>\n",
       "      <td>938668</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151336 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      created_at  \\\n",
       "9      2020-04-09 23:56:58+00:00   \n",
       "10     2020-04-09 23:56:51+00:00   \n",
       "28     2020-04-09 23:55:05+00:00   \n",
       "29     2020-04-09 23:54:47+00:00   \n",
       "30     2020-04-09 23:54:28+00:00   \n",
       "...                          ...   \n",
       "923637 2020-07-16 00:04:02+00:00   \n",
       "923644 2020-07-16 00:03:39+00:00   \n",
       "923652 2020-07-16 00:02:21+00:00   \n",
       "923656 2020-07-16 00:01:48+00:00   \n",
       "923668 2020-07-16 00:00:25+00:00   \n",
       "\n",
       "                                                     text      id   source  \n",
       "9       RT @TDANetwork: üìΩÔ∏è #TheWatchList panel assesse...      13  Twitter  \n",
       "10      $UMRX bouncing. EXTREMELY OVERSOLD #Coronaviru...      14  Twitter  \n",
       "28      $AAPL 4h/1h\\n\\nSometimes these wedges break hi...      32  Twitter  \n",
       "29      This week's Expired Signals are now published ...      33  Twitter  \n",
       "30      $SPY $QQQ $VXX $AAPL $BA $MSFT\\n\\nGuys, I figu...      34  Twitter  \n",
       "...                                                   ...     ...      ...  \n",
       "923637  RT @TATrades: Quick poll - how much do you (on...  938637  Twitter  \n",
       "923644           RT @NukemosS: China retaliating on $AAPL  938644  Twitter  \n",
       "923652  lows. This is shaping up for another nice sell...  938652  Twitter  \n",
       "923656  @_SeanDavid I could make a good case for why $...  938656  Twitter  \n",
       "923668  RT @MadMraket: We tend to spend lot of time in...  938668  Twitter  \n",
       "\n",
       "[151336 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_huggingface_twitter_data(stocks, start_date, end_date, output_dir):\n",
    "    \"\"\"\n",
    "    Load historical Twitter data from Hugging Face and filter for specified stocks.\n",
    "    \n",
    "    Args:\n",
    "        stocks (list): List of stock tickers (e.g., ['GME', 'AMC']).\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        output_dir (str): Directory to save output CSV.\n",
    "    \"\"\"\n",
    "    # Convert dates to UTC-aware datetime\n",
    "    start_dt = datetime.strptime(start_date, '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "    end_dt = datetime.strptime(end_date, '%Y-%m-%d').replace(tzinfo=pytz.UTC)\n",
    "    \n",
    "    dataset_name = \"StephanAkkerman/stock-market-tweets-data\"\n",
    "\n",
    "    df_filtered = pd.DataFrame()\n",
    "    \n",
    "    # for dataset_name in datasets_to_try:\n",
    "    print(f\"Attempting to load dataset: {dataset_name}\")\n",
    "    try:\n",
    "        dataset = load_dataset(dataset_name, split=\"train\", trust_remote_code=True)\n",
    "        df = dataset.to_pandas()\n",
    "        print(f\"Successfully loaded {dataset_name}\")\n",
    "            \n",
    "        # Ensure date column exists\n",
    "        date_column = 'created_at' if 'created_at' in df.columns else 'date'\n",
    "        if date_column not in df.columns:\n",
    "            print(f\"No date column in {dataset_name}. Skipping date filtering.\")\n",
    "            df['created_at'] = pd.NaT\n",
    "        else:\n",
    "            # Convert dates to UTC\n",
    "            df['created_at'] = pd.to_datetime(df[date_column], errors='coerce', utc=True)\n",
    "            \n",
    "        # Filter by date range\n",
    "        if df['created_at'].notna().any():\n",
    "            df = df[(df['created_at'] >= start_dt) & (df['created_at'] <= end_dt)]\n",
    "            \n",
    "        # Filter for stock tickers (case-insensitive)\n",
    "        stock_pattern = '|'.join([f'\\\\${t}' for t in stocks] + stocks)  # Match $GME or GME\n",
    "        df_filtered = df[df['text'].str.contains(stock_pattern, case=False, na=False)]\n",
    "            \n",
    "        if not df_filtered.empty:\n",
    "            df_filtered = df_filtered[['created_at', 'text', 'id']].copy()\n",
    "            df_filtered['source'] = 'Twitter'\n",
    "            print(f\"Found {len(df_filtered)} tweets from {dataset_name}\")\n",
    "        else:\n",
    "            print(f\"No matching tweets in {dataset_name}\")\n",
    "                \n",
    "    except requests.exceptions.SSLError as ssl_err:\n",
    "        print(f\"SSLError loading {dataset_name}: {ssl_err}\")\n",
    "        print(\"Try updating dependencies or checking network settings.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {dataset_name}: {e}\")\n",
    "    \n",
    "    if df_filtered.empty:\n",
    "        print(\"No Twitter data retrieved from Hugging Face datasets.\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "def collect_stock_social_data(stocks, start_date, end_date, output_dir):\n",
    "    \"\"\"\n",
    "    Collect Twitter and StockTwits data for specified stocks and save to CSV.\n",
    "    \n",
    "    Args:\n",
    "        stocks (list): List of stock tickers.\n",
    "        start_date (str): Start date in 'YYYY-MM-DD' format.\n",
    "        end_date (str): End date in 'YYYY-MM-DD' format.\n",
    "        output_dir (str): Directory to save output CSV.\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Fetch Twitter data from Hugging Face\n",
    "    df_twitter = fetch_huggingface_twitter_data(stocks, start_date, end_date, output_dir)\n",
    "    \n",
    "    # Combine datasets\n",
    "    # if not df_twitter.empty and not df_stocktwits.empty:\n",
    "    #     df_combined = pd.concat([df_twitter, df_stocktwits], ignore_index=True)\n",
    "    # elif if not df_twitter.empty:\n",
    "    #     df_combined = df_twitter\n",
    "    # # elif not df_stocktwits.empty:\n",
    "    # #     df_combined = df_stocktwits\n",
    "    # else:\n",
    "    #     df_combined = pd.DataFrame()\n",
    "    \n",
    "    # Save to CSV\n",
    "    if not df_twitter.empty:\n",
    "        output_path = f\"{output_dir}/stock_social_data.csv\"\n",
    "        df_twitter.to_csv(output_path, index=False)\n",
    "        print(f\"Saved data to {output_path}\")\n",
    "    else:\n",
    "        print(\"No data collected\")\n",
    "    \n",
    "    return df_twitter\n",
    "\n",
    "\n",
    "# Example usage\n",
    "output_dir = \"twitter_data\"\n",
    "collect_stock_social_data(stocks, start_date, end_date, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
